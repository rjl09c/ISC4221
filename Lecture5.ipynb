{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Data Mining\n",
    "\n",
    "Originally a statistical term of art for overusing data to draw invalid inferences\n",
    "\n",
    "*\"Bonferroni's theorem tells us that if there are many possible conclusions to draw, some of them will be true statistical reasons with no physical validity\"*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Data mining, the original meaning\n",
    "<img src=\"https://imgs.xkcd.com/comics/significant.png\" width=\"250\" height=\"250\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Thoughts on the need for data-mining\n",
    "\n",
    "*\"Drowning in Data yet Starving for Knowledge\"* - unknown \n",
    "\n",
    "*\"Computers have promised us a fountain of wisdom but delivered a flood of data\"* - William J. Frawley, Gregory Piatetsky-Shapiro, and Christopher J. Matheus\n",
    "\n",
    "*\"Where is the wisdom we have lost in knowledge? Where is the knowledge we\n",
    "have lost in information?\"* - T.S Eliot\n",
    "<img src=\"http://www.ncbi.nlm.nih.gov/core/assets/genbank/images/genbankgrowth.jpg\" width=\"250\" height=\"250\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## What Data Mining isn't: \n",
    "\n",
    "<s> *Data Mining, noun: “Torturing data until it confesses ... and if you torture it\n",
    "enough, it will confess to anything”* </s>\n",
    "\n",
    "<s> *\"An Unethical Econometric practice of massaging and manipulating the data to\n",
    "obtain the desired results*\" </s>\n",
    "\n",
    "Times change and words change with the times. (*Tempora mutantur, nos et mutamur in illis*, more or less)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Current Day Examples of Data Mining\n",
    "\n",
    "* Traveler patterns studied/analysed to manage the sale of discounted seats/hotel rooms rooms. \n",
    "\n",
    "* The connection between diapers and beer. From the user of data mining it was observed that customers who buy diapers are more likely to by beer than average. Supermarkets then placed beer and diapers nearby, knowing many customers would walk between them. Placing potato chips between diapers and beer increased sales of all three items.\n",
    "\n",
    "* Skycat and Sloan Digital Sky Survey - clustering sky objects by their radiation levels in different bands allowed astromomers to distinguish between galaxies, nearby stars,and many other kinds of celestial objects.\n",
    "\n",
    "* Comparison of the genotype of people with/without a condition allowed the discovery of a set of genes that together account for many cases of diabetes. This sort of mining will become much more important as the human genome is constructed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Big data tolls for thee\n",
    "\n",
    "<img src=\"http://i.imgur.com/gGs5f1d.png\" width=\"300\" height=\"400\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## The Component Fields of data mining\n",
    "\n",
    "* Statistics\n",
    "* Mathematics\n",
    "* Artifical Intelligence (*machine learning*)\n",
    "* Visualization\n",
    "* Information/Database sciences\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Stages of data mining\n",
    "* <s>Denial</s> Data gathering (data warehousing, web crawling, semi-legal metadata collection)\n",
    "* Data cleansing (elimating errors, corrupted data, unphysical outliers)\n",
    "* Feature extraction (obtaining only the interesting attributes of the data; i.e. timestamp for data that has no reason to be time-dependent)\n",
    "* Pattern extraction/discovery (the classical \"data-mining\" step)\n",
    "* Visualization\n",
    "* Evaluation of the results (not every discovered fact is useful or true.)\n",
    "  * Use you judgement\n",
    "  \n",
    "<img src=\"http://sparrowism.soc.srcf.net/home/piratesarecool4.gif\" width=\"400\" height=\"300\" />\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Clustering\n",
    "* Clustering strives to indetify groups/clusters of objects that behave similarly/or have similar characteristics. \n",
    "\n",
    "*Similarity is ofter quantified via some sort of distance function. \n",
    "\n",
    "* Has different names in different contexts \n",
    "  * Segmentation method (market studies)\n",
    "  * Unsupervised learning (neural network studies)\n",
    "\n",
    "* Cluster is a technique which attempts to find order in apparently unordered data. \n",
    "  * Data may be discrete or continuous. \n",
    "  \n",
    "We'll look at three types of clustering\n",
    " * Hierarchical clustering\n",
    " * K-means clustering\n",
    " * geometric clustering\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Hierarchical Clustering\n",
    "\n",
    "Clustering data points based on a tree-like hierarchical relationships \n",
    "\n",
    "In **agglomerative hierarchical clustering**, the data is grouped in a bottom up fashion; every data point starts out as a cluster of 1, then you begin grouping similar objects. \n",
    "\n",
    "The opposite approach is **divisive hierarchical clustering**; everything start outs in the same cluster, then you begin breaking off clusters based on differences. \n",
    "\n",
    "**The most important concept for clustering is how you quantify \"similarness\" of two different data points. Often times this will be a \"distance\" in some space.**\n",
    "\n",
    "Different clustering methods define this distance in different ways. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Measures of Distance\n",
    "\n",
    "Natural concept for data points in physical space (x,y,z); use Euclidean distance formula. \n",
    "\n",
    "There are other ways of doing it as well (infinity norm / max norm) \n",
    "\n",
    "In stating the distance between two objects, you need to define your distance. \n",
    "\n",
    "Often, our objects are not in Euclidean space (colors in an image, amino acid codons, etc...), yet we still need to quantify the distance between them. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Measures of Distance\n",
    "\n",
    "Let $A,\\ B$ and $C$ be clusters (which may consist of a single or multiple objects). WE denote the distance between $A$ and $B$ as $d(A,B)$ where $d(\\cdot,\\cdot)$ satisfies the following general properties by definiton. \n",
    "\n",
    "1. $d(A,A) = 0$\n",
    "2. $d(A,B) = d(B,A)$\n",
    "3. $d(A,B) \\ge 0$\n",
    "4. $d(A,B) + d(B,C) \\le d(A,C)$ \n",
    "\n",
    "If you decide on the Euclidean norm (or any vector norm), measuring the distance between two single objects is relatively simple; but how do define the distance between two groups of objects\n",
    "\n",
    "* Nearest neigbhor, furthest, average, centroid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Measures of distance example:\n",
    "\n",
    "Imagine we have two words we want to quantify the distance between; You can define a path from the first word to the second word by changing one letter at a time to make another word (a legal word (scrabble legal)). \n",
    "\n",
    "Lets look at an example of the distance between GOLF and WORD\n",
    "\n",
    "GOLF $\\rightarrow$ GOLD $\\rightarrow$ COLD $\\rightarrow$ CORD $\\rightarrow$ WORD\n",
    "\n",
    "The distance in this metric is 4, for GOLF and WOLF it would be 1. \n",
    "\n",
    "This metric satisfies all of our neccesary properties of a distance. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Agglomerative Hierachical Clustering\n",
    "\n",
    "Bottoms up grouping of objects. \n",
    "\n",
    "Starting with N objects we want to cluster, we let each object initially be it's own cluster. This gives us N clusters. \n",
    "\n",
    "Our first step is to pick the two closest (however we define it) clusters (objects in this first step) and form a cluster with them. We now have N-1 clusters and now record that in the first step,  clusters i and j were merged. \n",
    "\n",
    "Our second step, we again merge the two closest clusters. This may involve merging our two object cluster with a third, or merging two individial objects for a new cluster. \n",
    "\n",
    "We continue until we have a single cluster, or a user specified number of clusters. \n",
    "\n",
    "How do we define distance between one object, and a cluster of multiple objectss?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Single Linkage Hierarchial Clustering\n",
    "\n",
    "This clustering technique makes a specific choice for determining closeness between clusters; the distance between two clusters is the distance between the closest elements in the two clusters. \n",
    "\n",
    "<img src=\"http://i.imgur.com/AqylMZc.png\" width=\"300\" height=\"400\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## SLHC\n",
    "If $A$ consists of #n# objects $\\alpha_i$ and $B$ consists of $m$ objects $\\beta_j$, then the distance between $A$ and $B$ would be given as \n",
    "\n",
    "$$ d(A,B) = \\min(d(\\alpha_i,\\beta_j)) \\text{ for } i=1,n, j =1,m$$\n",
    "\n",
    "The distance between all possible object pairs is computed, and the the minimum value of these is said to be the distance between clusters A and B. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Clustering in Python \n",
    "Lets initalize some stuff first. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAD7CAYAAABDld6xAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSmHpx37CtCkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7bc3e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# needed imports\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "np.set_printoptions(precision=5, suppress=True) \n",
    "a = [[3,0], [0,1], [1,1], [6,1], [2,2], [4,2], [7,3], [6,5], [4,7], [7,7], [0,8], [2,8]]\n",
    "\n",
    "a = np.asarray(a)\n",
    "plt.scatter(a[:,0], a[:,1])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Clustering in Python\n",
    "Now lets do some clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEZCAYAAACervI0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x3f7beb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Z = linkage(a, 'single', 'euclidean')\n",
    "plt.title('Hierarchical Clustering Dendrogram')\n",
    "plt.xlabel('sample index')\n",
    "plt.ylabel('distance')\n",
    "t = dendrogram(\n",
    "    Z,\n",
    "    leaf_rotation=90.,  # rotates the x axis labels\n",
    "    leaf_font_size=8.,  # font size for the x axis labels\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Clustering in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src=\"http://i.imgur.com/pY1IX6Z.png\" width=\"500\" height=\"500\" />\n",
    "\n",
    "Single linkage clustering tends to cluster items due to one outlier in a cluster grabing vaguely close points. We can avoid this with complete linkage clustering. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Completed Linkage Hierarchical Clustering \n",
    "\n",
    "The opposite of SLHC. \n",
    "Looks at the maximum distance between objects in two clusters. \n",
    "$$ d(A,B) = \\max(d(\\alpha_i,\\beta_j)) \\text{ for } i=1,n, j =1,m$$\n",
    "\n",
    "At each step, the two clusters with the minimalist maximum distance are clustered. \n",
    "\n",
    "<img src=\"http://i.imgur.com/aRDJwAC.png\" width=\"400\" height=\"400\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### CLHC in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAEZCAYAAACD/A7qAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYDczy4yD3cwsMw52M7PMONjNzDLz/5HgmjLc3bmiAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x8617748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### CLHC in Python\n",
    "Z = linkage(a, 'complete', 'euclidean')\n",
    "plt.title('Hierarchical Clustering Dendrogram')\n",
    "plt.xlabel('sample index')\n",
    "plt.ylabel('distance')\n",
    "t = dendrogram(\n",
    "    Z,\n",
    "    leaf_rotation=90.,  # rotates the x axis labels\n",
    "    leaf_font_size=8.,  # font size for the x axis labels\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Other Hierachical clusterings \n",
    "\n",
    "* Average linkage hierarchical clustering\n",
    "  * $d(A,B) = \\frac{1}{mn} \\sum_{i=1}^n\\sum_{j=1}^m d(\\alpha_i, \\beta_j)$\n",
    "  \n",
    "* Centroid linkage hierarchical clusterings\n",
    "  * $d(A,B) = ||\\bar\\alpha-\\bar\\beta||_2$\n",
    "  \n",
    "  $$\\bar\\alpha= \\frac{1}{n}\\sum_{i=1}^n \\alpha_i$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Hierarchical Clustering Utility\n",
    "Hierachical Clustering is useful when the data is thought to have a family/evolutionary relationship\n",
    "\n",
    "Clusters/Subclusters formed based on degree of similarity\n",
    "\n",
    "Not useful if there is no reason to assume a hierarchy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## K-Means Clustering\n",
    "\n",
    "K-Means clustering looks for K average values about which the data can be clustered. \n",
    "\n",
    "We are not as interested in finding a family history but rather breaking our\n",
    "data into K groups.\n",
    "\n",
    "Example: 435 House Congressional districts to be formed. \n",
    "\n",
    "Need to quantify these averages and energies in order to implement. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Averages/Energy Function\n",
    "\n",
    "Averages are often used as a measure of center for a set of data; a single number to represent a set of numbers. We can quantify this more rigorously/mathematically as follows: \n",
    "\n",
    "Let $\\bar x$ be the average of the set $X = \\{x_1, x_2, \\ldots x_n\\}$, Then $\\bar x$ is the unique number which minimizes the energy function\n",
    "\n",
    "$$\\mathcal{E}(c,X) = \\frac{1}{2}\\sum_{i=1}^n(c-x_i)^2$$\n",
    "\n",
    "Which is to say \n",
    "\n",
    "$$ \\bar x = \\min_{c\\in\\mathcal{R^1}}\\frac{1}{2}\\sum_{i=1}^n(c-x_i)^2$$\n",
    "\n",
    "How do we prove this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Averages/Energy Function\n",
    "\n",
    "Take the derivative of the energy function with regard to c, and set it to 0, solve for c. \n",
    "\n",
    "$$\\frac{\\partial\\mathcal{E}(c,X)}{\\partial c} = \\frac{1}{2}\\sum_{i=1}^n2(c-x_i)=0$$\n",
    "\n",
    "$$ \\sum_{i=1}^n c = \\sum_{i=1}^n x_i$$\n",
    "\n",
    "$$c = \\frac{1}{n}\\sum_{i=1}^n x_i$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## K-means and the energy function\n",
    "\n",
    "Now that we view an average as the minimum of an energy function, we can generalize the concept and use it to form a procedure for K-means clustering.\n",
    "\n",
    "Assume we have a set of $K$ centers, $c_j$, and you have more than one \"average\". We want to divide the data into $K$ clusters $C_j$ and find the points $c_j$ such that the energy function:\n",
    "\n",
    "$$\\mathcal{E} = \\sum_{j=1}^K \\Big[ \\sum_{x_i \\in C_j} ||c_j - x_i||_2^2\\Big]$$\n",
    "\n",
    "Is minimized. This is the basis of K-means clustering. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Clusters and Centers\n",
    "<img src=\"http://i.imgur.com/RqtxXtR.png\" width=\"400\" height=\"400\" />\n",
    "\n",
    "Here we have 100 points and 5 random 'centers' $c_j$. We cluster the points by\n",
    "determining which of the 5 'centers' each point is closest to. The problem is,\n",
    "these points are not actual centers of the clusters and don’t minimize our energy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## The K-means algorithm / LLoyd's method\n",
    "\n",
    "Given a set of $N$ points in $\\mathcal{R}^d,   X = \\{\\vec x_i\\}^N_{i=1}$, we want to cluster this data into $K$ groups.\n",
    "\n",
    "The goal is to find K points $c_j$ such that the energy \n",
    "$$\\mathcal{E} = \\sum_{j=1}^K \\Big[ \\sum_{x_i \\in C_j} ||c_j - x_i||_2^2\\Big]$$\n",
    "\n",
    "is minimized. The cluster $C_j$ is the set of points in $X$ which are closer to $c_j$ than any other $c_i$\n",
    "\n",
    "For the initializiation step, we choose K points called centers or generators and denote them by $\\vec c_i$, $i=1,\\ldots, K$. They can be random, but other approaches may be better depending on the problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## The K-means algorithm\n",
    "\n",
    "**Step 1:** For each point $\\vec x_i$ , determine $\\vec c_j$ such that\n",
    "$$||x_x - c_j || \\leq ||x_i-c_n||\\text{ for all }n = 1, \\ldots N$$\n",
    "\n",
    "This is the clustering step. Every point gets associated with a single cluster. \n",
    "\n",
    "There is no expectation that these initial clusters will minimize our energy function. In fact, some clusters may be entirely empty (some values of $c_j$ may be associated with no points in $X$). \n",
    "\n",
    "So we now construct an iterative process were we move $c_i$ to the center of each cluster and start again. \n",
    "\n",
    "**Step 2:** Compute a new set of centers/generators such that\n",
    "\n",
    "$$ c_j =\\text{the average of all points in the }j\\text{th cluster}$$\n",
    "\n",
    "**Step 3:** Check for convergence. if not converged, go to step 1. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Evolution of K-means\n",
    "<img src=\"http://i.imgur.com/oOi0IZi.png\" width=\"600\" height=\"600\" />\n",
    "\n",
    "In this example we have 10 points on [0, 10] × [0, 10]. The initial generators aredenoted by red circles and after 3 iterations, they have moved to the black circles. The blue points are in one cluster and the red points in another"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Evolution of K-means\n",
    "\n",
    "<img src=\"http://i.imgur.com/lGwq8LR.png\" width=\"600\" height=\"600\" />\n",
    "\n",
    "This is our 100 points from a previous slide that have been clustered using KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Convergence of K-means\n",
    "\n",
    "To gauge the quality of our clustering, we can look at the variance quantity that we have previously discussed. Recall that the variance of a set of points is given as. \n",
    "\n",
    "$$\\text{var}(x) = \\frac{1}{n} \\sum_{i=1}^n(x_i - \\bar x)^2$$\n",
    "\n",
    "The variance can thus be thought of something like the average distance between your data points and their average. If a data set has a small variance, most of the data is close to the average. \n",
    "\n",
    "If we have multiple clusters for our data instead of a single average, the discrete cluster variance is defined as \n",
    "$$ \\frac{1}{n_j} \\sum_{x_i \\in C_j} ||x_i - c_j||^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Convergence of K-Means\n",
    "\n",
    "K-means converges because \n",
    "* Whenever a point is assigned to a new cluster, the sum of the squared distances of each point in the cluster to its assigned cluster center is reduced.\n",
    "\n",
    "* Whenever a cluster center is moved the sum of the squared distances of thedata points from their currently assigned cluster centers is reduced. Thus the cluster variance is reduced.\n",
    "\n",
    "* If points are no longer moved between clusters, then the algorithm has converged. \n",
    "\n",
    "Total cluster variance should be reduced at each iteration, but there is no guarantee to find the global minimum (the set of cluster centers that gives the lowest total energy over all possible sets of cluster centers). \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## K-means: Global vs Local minimum. \n",
    "<img src=\"http://i.imgur.com/oI9no54.png\" width=\"600\" height=\"600\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## K-means: Global vs Local minimum. \n",
    "\n",
    "Some strategies to find the global minimum for a K-means problem\n",
    "\n",
    "* Run the algorithm many different times with many different starting points and compute the energies fo each, selecting the set of centers corresponding to the smallest final energy in all these runs. \n",
    "\n",
    "* Use some prior information about your data to make a more intelligent choice for your initial generators than random. \n",
    "\n",
    "* Use quasi-random sampling to ensure a more uniform sampling your domain for your initial generator positions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Implementing K-means\n",
    "\n",
    "**Initalization step**: Set $k$, the number of clusters you wish to form, the input data to be clustered ($n$ records, $x_i$), and the maximum number of maximum iterations, and your initial generator points.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "```\n",
    "def KMeans(k,c_init,x,n,max_iter):\n",
    "    c = cinit\n",
    "    for nit in range(0,max_iter):\n",
    "        for i = in range(0,n-1):\n",
    "            find center c[j] which x[i] is closest to\n",
    "            increment counter n[j] for number of data points in cluster C[j]\n",
    "            increment sum of each coordinate of all points in cluster C[j]\n",
    "        move centers c[j] by taking average of all points in C[j]\n",
    "         \n",
    "        check for convergence\n",
    "         \n",
    "        if (converged)\n",
    "        break\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## K-means algorithm implementation considerations\n",
    "\n",
    "The main work each iteration is to finding the center each record is associated with. \n",
    "* For small problems, you'll likely take the brute force approach and just calculate the distance between every point and every center, and then just select the minimum. \n",
    "\n",
    "When to terminate the K-means algorithm\n",
    "\n",
    "* Convergence is formally acheived when the cluster centers $c_j$ stop moving from one iteration to the next. For practical purposes, you can say that any cluster movement smaller than some tolerance indicates convergence for that cluster.\n",
    "* When all cluster movement falls beneath that tolerance, total convergence is acheived and your algorithm can exit. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## K-means algorithm for image compression\n",
    "* If we have a color image we know that each pixel is represented by three RGB values creating a myriad of colors.\n",
    "\n",
    "* Our your computer monitor you have essentially an unlimited number of colors ($256 ^ 3$)available but on a printer you have less. \n",
    "\n",
    "* We can use K-Means to accomplish this image compression. In the lab we will find which 32 colors best represent the image.\n",
    "\n",
    "* To do this, we initiate our probabilistic Lloyd’s algorithm with k generators which are numbers between 0 and 255; we can simply choose the generators randomly\n",
    "\n",
    "* In Lloyd’s algorithm we need to sample each record so in our application this means to sample the image; i.e., sample a random pixel. If the image is not too large, then we can simply sample every pixel in the image.\n",
    "\n",
    "* We then proceed with the algorithm until convergence is attained.\n",
    "\n",
    "* After convergence is achieved we know the best $k$  shades of gray to represent our image so our final step is to replace each color in our original matrix representation of the image with the converged centroid of the cluster it is in.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## K-Means image compression\n",
    "\n",
    "<img src=\"http://i.imgur.com/ZL1Nkme.png\" width=\"600\" height=\"600\" />\n",
    "\n",
    "\n",
    "Original RGB image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## K-means image compression\n",
    "\n",
    "<img src=\"http://i.imgur.com/u8Ldxxk.png\" width=\"600\" height=\"600\" />\n",
    "\n",
    "\n",
    "K-means compressed image with only 8 RGB colors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " # Weighted K-Means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Classification Problems\n",
    "\n",
    "The problem of assigning an object into one of a preselected group. \n",
    "Examples include \n",
    "* Classifying e-mails as spam or innocuous based on message header and content. \n",
    "* Classifying cells as benign or cancerous based on scan results\n",
    "* Classifying galaxies (spiral, elliptical, irregular) based on their morphology.\n",
    "* Classifying consumers as potential customers based on their purchase history. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Classification Terminology\n",
    "\n",
    "Each record in a data set is known as an **instance** and is characterized by the **attribute set** $x$ and the **target attribute/class label** $y$\n",
    "\n",
    "The classification problem is the problem of finding a target function $f$ that maps each attribute set $x$ to on of the predetermined class labels $y$. The target function is our classification model. \n",
    "\n",
    "Generally, you will use a training set to build a classification model. \n",
    "\n",
    "Classification models can be used for \n",
    "\n",
    "* Descriptive Modeling - serving as an explanatory tool to distinguish between objects of different classes\n",
    "\n",
    "* Predictive Modeling - predicting the class labels for unknown records. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Attribute types\n",
    "\n",
    "There are 4 types of attributes\n",
    "\n",
    "* nominal : different names/labels (brown/blue/green for eye color)\n",
    "* ordinal : ordered attribute (hot/mild/cold, or small/medium/large)\n",
    "* interval: differences in values are meaningful (dates, temperature)\n",
    "* ratio   : differences in ratios are meaninful (mass, age)\n",
    "\n",
    "Attributes can be discrete or continuous. \n",
    "\n",
    "Discrete attributes can be nominal like zipcodes/SSN or just numerical. Binary attributes are a special case of attribute that are either true or not (married or unmarried, mammal, not mammal). They can be represented as a 0 and 1 an are often dubbed Boolean attributes. \n",
    "\n",
    "Continuous attributes have values which are real numbers (temperature, weight, salary). \n",
    "\n",
    "Classification techniques work best for data which is binary or nominal. Often times, continuous data is transformed into ordinal (from a salary value to high-income, middle-income, and low-income). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## General Approach to Solving Classification Problems\n",
    "\n",
    "The goal is to build a classification model from an existing set of data systematically. The model should both:\n",
    "\n",
    "* Accurately Describe the Training Data\n",
    "* Correctly predict the class labels of unseen records not in the training data. \n",
    "\n",
    "Techniques include:\n",
    "\n",
    "* Decision tree classifiers\n",
    "* rule-based classifiers\n",
    "* neural networks\n",
    "* support vector machies\n",
    "* Bayes classifiers\n",
    "\n",
    "Each technique uses a learning algorithm to indentify a model that best fits the relationship between the attribute set and the class label from training data. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Steps to the General Approach for Classification Problems\n",
    "\n",
    "1. Provide a training set of data whose class labels are known.\n",
    "2. Apply one of the techniques above to build a classification model using the training set. \n",
    "3. Apply the model to a test set of data to determine class labels. \n",
    "4. Evaluate the performance of the model based of the number of correct/incorrect predictions in the test set. Accuracy and error rate can be computed for these models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Test Set Example\n",
    "\n",
    "Consider the case where we have a classification model to classify records as either Class A or Class B, and using the model on the test set reveals the following results. \n",
    "\n",
    "| Actual Class  |A   | B   |\n",
    "| ------------- |:--:| ---:|\n",
    "| Class A       | 43 | 10  |\n",
    "| Class B       | 12 | 35  |\n",
    "\n",
    "Of the 100 records in the test set, 43 were correctly assigned to class A, 10 were incorrectly assigned to class A. 12 were incorrectly assigned to class B, and 35 were correctly assigned to class B. That gives us an accuracy of $78/100=78\\%$, and an error rate of $22\\%$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Decision Tree Classifiers\n",
    "\n",
    "The idea behind decision trees is to pose a series of questions about the characteristics we are interested in. The choice of questions is chosen carefully to develop to classification model. \n",
    "\n",
    "Example: Suppose we have a list of vertebrates and we want to classify them\n",
    "as mammals or non-mammals. Below is a possible decision tree for classifying a\n",
    "vertebrate. Note the following terminology:\n",
    "\n",
    "* root node: no incoming edges and zero or more outgoing edges. \n",
    "* internal node: exactly one incoming edge and two or more outgoing edges\n",
    "* leaf node: exactly one incoming and no outgoing edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Decision Tree Classifier Example\n",
    "\n",
    "Suppose we want to use this tree to classify a penguin which has the following attributes. \n",
    "<img src=\"http://i.imgur.com/oWrpFcT.png\" width=\"300\" height=\"300\" />\n",
    "\n",
    "| name |body temp |gives birth  | class |\n",
    "| ------------- |:--:| :---:| --------: \n",
    "| penguin       | warm blooded | no   | ?|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Decision Tree Classifier Approach:\n",
    "\n",
    "As there are exponentially many decision trees that can be constructed from a set of given attributes, so we are likely unable to find the single best decision tree; instead, we build our decision tree on the single best question we can ask right now. This is another example of a **greedy** algorithm. \n",
    "\n",
    "Recall that greedy algorithms are characterized by the fact that the choice at any given step fits the following two criteria:\n",
    "* It is the best local choice available among all feasible choices available that step\n",
    "* The choice is irrevocable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Decision tree classifier example 2:\n",
    "Suppose we want to build a decision tree to predict whether a person\n",
    "will default on his/her car loan payments. We collect data from previous bor-\n",
    "rowers and accumulate the following training set. The attributes we summarize\n",
    "are: (i) homeowner (binary attribute), (ii) marital status (nominal/categorical), (iii) annual income (continuous ). Our target class label is binary and is whether that person defaults on the loan payments.\n",
    "\n",
    "\n",
    "<img src=\"http://i.imgur.com/BSYqDIW.png\" width=\"600\" height=\"600\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Decision Tree Classifier Example: Hunt's Algorithm\n",
    "\n",
    "Hunt's algorithm Builds a decision tree in a recursive manner; the records are subsequently divided into smaller subsets until the records belong to the same class. \n",
    "\n",
    "Step 0: Check to make sure all records in the training set don't all have the same value in the target attribute (defaulted in the above example). If you're building a classifying model, there needs to be differences in the target attribute. \n",
    "\n",
    "Step 1: Determine your question; for now we'll just ask them in order in the table, so we first check home ownership. We not that all three home owners did not default, so that is a leaf. However, some non-home owners defaulted and others didn't so we need to subdivide further. \n",
    "\n",
    "Step 2: Our second question/criteria will be marital status; here we note that all married borrowers repaid their loans so that is a leaf; however, not all single/divorced borrowers repaid, so we need to subdivide further. \n",
    "\n",
    "Step 3: Our  third criteria is annual income. The group of non-homeowners who\n",
    "are single or divorced is divided by < 80K or > 80K. In this case the individuals making more than 80K defaulted and those making less did not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Decision Tree Classifier Example: Hunt's Algorithm\n",
    "\n",
    "Resulting decision tree\n",
    "<img src=\"http://i.imgur.com/xgiTRaF.png\" width=\"600\" height=\"600\" />\n",
    "\n",
    "Of course if we ask the questions in a different order we get a different decision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Decision Tree Classifier Example: Hunt's Algorithm\n",
    "<img src=\"http://i.imgur.com/Gj2zFHF.png\" width=\"600\" height=\"600\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Hunt's algorithm\n",
    "\n",
    "Each step is recursive, in that we attempt to partition the training records into successively similar subsets. \n",
    "\n",
    "To describe the method more abstractly, let $y = \\{y_1, y_2,\\ldots, y_l\\}$ be the class labels (default or didn't default in the abvoe example) and let $\\mathcal{D}_i$ be the $i$th subset of the training set associated with node $i$ (either leaf, root, or internal node)\n",
    "\n",
    "The algorithm then \n",
    "\n",
    "Checks to see if all records in $\\mathcal{D}_i$ belong to the same class $y_i$ \n",
    "* If so, i is a leaf node\n",
    "* If not, choose an attribute test condition (question) to partition the record into smaller subsets. A child node is created for each outcome of the test condition and the records in $\\mathcal{D}_i$ are distributed according to the outcome of each test condition. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Hunt's algorithm considerations\n",
    "Some child nodes may be empty if none of the training records have the combination of attributes associated with each node. In this case we just declare it a leaf node with the same class label as the majority class of training records associated with its parent node.\n",
    "\n",
    "Also suppose we had separated our home owners and the ones who owned homes had identical attributes but different class labels, i.e., some defaulted\n",
    "and some didn’t. We couldn’t separate these records any further. In this\n",
    "case we declare it a leaf node with the same class label as the majority\n",
    "\n",
    "#### When should we stop tree growth?\n",
    "\n",
    "The recursive algorithm needs a termination criteria. Typically the algorithm will go as far as it can (until in splits everything up or gets to the point it can no longer split things based on the attributes). You may make the informed decision to terminate it sooner. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Hunt's algorithm: Attribute Test Conditions\n",
    "\n",
    "The \"asking the right question\" decision. What makes a good question at any given step? First, lets look at what kinds of questions we can ask for a given attribute type.\n",
    "\n",
    "* Binary: The easiest; they are or they aren't, 0 or 1. \n",
    "\n",
    "* Nominal: can be split a variety of ways, some intelligent grouping will likely be required. \n",
    "\n",
    "* Ordinal: can produce two or more splits (small/medium/large)\n",
    "\n",
    "* Continuous Attributes: Usually use a logical comparison to test. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Nominal Attribute Splitting\n",
    "<img src=\"http://i.imgur.com/smif5Je.png\" width=\"600\" height=\"600\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Hunt's algorithm: Node purity measurues\n",
    "\n",
    "Hunt's algorithm goal is to subdivide everything into a leaf node as quickly as possible; So your goal is at any given step is to ask a question that splits your dataset at that set into as many \"pure\" subsets as possible. Pure here indicates that all members of that subset belong to the same class.  \n",
    "\n",
    "Letting $p(i|t)$ be equal to the fraction of records belonging to class $i$ at a given node $t$, we can write the following measures of pureness at any given node. \n",
    "\n",
    "$$\\text{Gini}(t) = 1 - \\sum_{i=1}^k (p(i|t))^2$$\n",
    "\n",
    "$$\\text{Classification error}(t) = 1 - \\max_{1\\leq i\\leq k}(p(i|t))$$\n",
    "\n",
    "$$\\text{Entropy}(t) = - \\sum_{i=1}^k(p(i|t))\\log_2 p(i|t)$$\n",
    "\n",
    "The first two are related to standard norms. Entropy is a similar measure that quantifies the amount of \"randomness\" or \"orderness\\organization\" in a set of data. Pure data has a very strong orderness and thus a very low entropy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Hunt's algorithm: Node purity measurues\n",
    "Consider the purity measures for nodes containing 2 different classes of objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:9: RuntimeWarning: divide by zero encountered in log2\n",
      "C:\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:9: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x8b56d68>,\n",
       " <matplotlib.lines.Line2D at 0x8b56f28>,\n",
       " <matplotlib.lines.Line2D at 0x8b68550>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAEACAYAAABWLgY0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x8a159b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t = np.linspace(0,1)\n",
    "gini = 1 - (t**2 + (1-t)**2)\n",
    "classification = np.zeros(len(t))\n",
    "count = 0\n",
    "for i in t:\n",
    "    \n",
    "    classification[count] = 1 - max(i, 1-i)\n",
    "    count = count + 1\n",
    "entropy = - (t*np.log2(t)+ (1-t)*np.log2(1-t))\n",
    "plt.plot(t, gini, 'r', t, classification, 'b', t, entropy, 'g')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Gain\n",
    "\n",
    "To determine how a test condition performs, we compare the degree of impurity of the parent nodes before splitting with the impurity of the child nodes after splitting (say some weighted average). The larger the difference, the better the test condition. \n",
    "\n",
    "The gain ($\\Delta$) is a measure that can determine how good a split you are making; in a greedy algorithm like Hunts, you will choose a  test critera that has the best gain at any given step. \n",
    "\n",
    "If $I$ defines the impurity measure of our choice, and we split some parent node containing $N$ records into $k$ child nodes which each contain $N_j$ records in the node $j$, the gain of this splitting is given by:\n",
    "\n",
    "$$\\Delta = I_{\\text{parent}}-\\sum_{j=1}^k \\frac{N_j}{N}I_j$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
